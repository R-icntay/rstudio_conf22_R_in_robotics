<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-0.9.387">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Ian Muchiri and Eric Wanjau">

<title>A touch of R in robotics - 1&nbsp; Speech to text</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<link href="./02_kinematics.html" rel="next">
<link href="./index.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link id="quarto-text-highlighting-styles" href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script defer="" src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Speech to text</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">A touch of R in robotics</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_speech_2_text_via_azure.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Speech to text</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_kinematics.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Manipulator kinematics</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03_board_mapping.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Board mapping</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04_aRduino.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">R and Arduino</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Summary</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"> <span class="header-section-number">1.1</span> Introduction</a></li>
  <li><a href="#recording-audio-in-r-using-the-audio-package" id="toc-recording-audio-in-r-using-the-audio-package" class="nav-link" data-scroll-target="#recording-audio-in-r-using-the-audio-package"> <span class="header-section-number">1.2</span> Recording Audio in R using the audio Package</a>
  <ul class="collapse">
  <li><a href="#recording-audio" id="toc-recording-audio" class="nav-link" data-scroll-target="#recording-audio"> <span class="header-section-number">1.2.1</span> Recording Audio</a></li>
  </ul></li>
  <li><a href="#house-keeping-on-azure" id="toc-house-keeping-on-azure" class="nav-link" data-scroll-target="#house-keeping-on-azure"> <span class="header-section-number">1.3</span> House Keeping on Azure</a></li>
  <li><a href="#speech-to-text-api-call" id="toc-speech-to-text-api-call" class="nav-link" data-scroll-target="#speech-to-text-api-call"> <span class="header-section-number">1.4</span> Speech-to-text API call</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title d-none d-lg-block"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Speech to text</span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>





<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Ian Muchiri and Eric Wanjau </p>
          </div>
  </div>
    
    
  </div>
  

</header>

<p>This notebook contains a step by step guide on how to record audio in R using the <a href="https://cran.r-project.org/web/packages/audio/audio.pdf">audio package</a> and convert the recording to text using Microsoft Azure Cognitive Services, specifically the <a href="https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/rest-speech-to-text-short">speech-to-text service</a>.</p>
<section id="introduction" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1.1</span> Introduction</h2>
<p>I recently found myself working on a chess play automation project. The user would issue a voice command describing the location of the piece they want to move and their desired destination location, the data would then processed and a chess move made. This was so cool and being the R-nista that I am (i don’t think this is a word, i have only come across Pythonistas ) ,I thought to myself, maybe this can also be done in R and voila, this article was born. For any feedback feel free to reach out at <a href="https://twitter.com/Entity_4004">Ian</a></p>
</section>
<section id="recording-audio-in-r-using-the-audio-package" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="recording-audio-in-r-using-the-audio-package"><span class="header-section-number">1.2</span> Recording Audio in R using the audio Package</h2>
<p>We begin with the input which we plan to transcribe. In order to record audio,we need to install and load the audio package</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">#install the audio package</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">"audio"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We then proceed to setup the audio driver which we will use to record as shown below:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Load the library</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(audio)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Check which audio driver is set</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="fu">current.audio.driver</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co">#if there is no driver set, view what drivers are available</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">audio.drivers</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co">#from the list provided, set which driver to use (default driver is always best)</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.audio.driver</span>(<span class="cn">NULL</span>)<span class="co"># sets the default audio driver</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co">#option 2</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.audio.driver</span> (insert_name_here ) <span class="co">#sets the audio driver to a driver other than the default</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Checks and verifies that indeed the audio driver is set as per the command above</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">current.audio.driver</span>() </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="recording-audio" class="level3" data-number="1.2.1">
<h3 data-number="1.2.1" class="anchored" data-anchor-id="recording-audio"><span class="header-section-number">1.2.1</span> Recording Audio</h3>
<p>Some of the key parameters in audio processing which we are going to encounter during this exercise include:</p>
<p><strong>Sample rate:</strong> This is the number of times per second a sound is sampled and recorded.Therefore, if we use a sampling rate of say 8000 Hertz, a recording with a duration of 5 seconds will contain 40,000 samples (8000 * 5). The industry standard sampling rate commonly used is 44100 Hertz.</p>
<p><strong>Mono vs Stereo:</strong> If you are a sound enthusiast, you’ve probably come across these terms. Simply put, Mono sound is recorded and played back using only <em>one audio channel</em> e.g.&nbsp;a guitarist recording using one mic to pick up sound of the guitar and Stereo sound is recorded and played through <em>more than one channel.</em></p>
<p>In our case we will use one audio channel(mono) and a sampling rate of 44100Hz. That being said let’s start our recording</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Set our recording time</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>rec_time <span class="ot">&lt;-</span> <span class="dv">5</span> </span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co">#Recording</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>Samples<span class="ot">&lt;-</span><span class="fu">rep</span>(<span class="cn">NA_real_</span>, <span class="dv">44100</span> <span class="sc">*</span> rec_time) <span class="co">#Defining number of samples recorded</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="st">"Start speaking"</span>)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>audio_obj <span class="ot">&lt;-</span><span class="fu">record</span>(Samples, <span class="dv">44100</span>, <span class="dv">1</span>) <span class="co">#Create an audio instance with sample rate 44100 and mono channel</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="fu">wait</span>(<span class="dv">6</span>)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>rec <span class="ot">&lt;-</span> audio_obj<span class="sc">$</span>data <span class="co"># get the recorded data from the audio object</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="co">#Save the recorded audio</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="fu">file.create</span>(<span class="st">"sample.wav"</span>)<span class="co">#gets created in your current working directory </span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="fu">save.wave</span>(rec,<span class="st">"Insert_path_to_sample.wav_here"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>On recording and saving the audio file to <code>sample.wav</code> , we have to clear the audio instance object <code>audio_obj</code> before proceeding to make the next recording. From the audio package documentation, this is achieved by using the <code>close(con,…)</code> method, where <code>con</code> is the audioInstance object .However, using this method proved to be cumbersome as it causes the console to freeze anytime you want to record audio for more than one time. After doing some research, I discovered that restarting the console clears the audio instance object therefore allowing for one to record audio multiple times with no issue. I know this is not an elegant solution (more like tying duct tape around a leaking pipe )and i am actively looking for a better solution to fix this issue. For now, we go by the saying: if it works, don’t touch it and implement this step to clear the audio instance object.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">.rs.restartR</span>() <span class="co"># clear the audio instance object(looking for a more elegant solution)</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="fu">wait</span>(<span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Play the recording we just created just to confirm that indeed we recorded something.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">play</span>(rec)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>That’s it for our input. We now proceed to process this and transcribe the audio we just recorded</p>
</section>
</section>
<section id="house-keeping-on-azure" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="house-keeping-on-azure"><span class="header-section-number">1.3</span> House Keeping on Azure</h2>
<p>First we begin with some light housekeeping, i.e setting up a <a href="https://docs.microsoft.com/en-us/azure/cognitive-services/what-are-cognitive-services">Cognitive Services resource</a> in our Azure subscription. You can create a free Azure account <a href="https://azure.microsoft.com/en-gb/">here</a> and if you have an account already, you can skip this step.</p>
<p>We then proceed to create a cognitive resource group by following these steps:<span class="math inline">\\</span> 1. Open the Azure portal <code>https://portal.azure.com</code> and sign in using your Microsoft account.<span class="math inline">\\</span> 2. Click <strong>+ Create a resource</strong> and on the search bar, type <strong>Speech</strong>, click <strong>create</strong> and create a Cognitive service resource with the following settings:</p>
<ul>
<li><p>Subscription: <em>Enter your Azure subscription</em></p></li>
<li><p>Resource group: <em>Create one with a unique name or an existing one</em></p></li>
<li><p>Region: <em>Choose any</em></p></li>
<li><p>Name: <em>Enter a unique name</em></p></li>
<li><p>Pricing tier: <em>Standard S0</em></p></li>
<li><p>Select I have read and understood the notices</p></li>
<li><p>Click on <strong>Review + create</strong> and we are good to go.</p></li>
</ul>
<p>As a guide, these are the settings I used however, you can go ahead and get creative with the names.</p>
<p><img src="images/creating%20speech%20service.png" class="img-fluid"></p>
</section>
<section id="speech-to-text-api-call" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="speech-to-text-api-call"><span class="header-section-number">1.4</span> Speech-to-text API call</h2>
<p>Since now we have our audio sample input <code>sample.wav</code> ,we can now go ahead to the transcribing bit. It is noteworthy that the speech to text rest API for short audio has several limitations which are:</p>
<ul>
<li><p>Requests cannot contain more than 60 seconds of audio. For batch transcriptions and custom speech use <a href="https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/rest-speech-to-text">Speech to Text API v3.0</a></p></li>
<li><p>The API does not provide partial results.</p></li>
<li><p>It does not support Speech translation. For translation, you can checkout the <a href="https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/speech-sdk">Speech SDK</a></p></li>
</ul>
<p>Now that we are done with that, we can then go ahead and get coding.</p>
<p><strong><code>Note:</code></strong> To access the speech service we just created from R, we need the <strong>URL of the endpoint</strong>, <strong>location/region details</strong> and <strong>KEY 1 &amp; 2</strong> parameters. These can be found in the azure portal under <strong>Keys and Endpoint</strong> page of your cognitive service resource as illustrated below:</p>
<p><img src="images/keys%20and%20endpoints.png" class="img-fluid"></p>
<p>Copy these details and save them since we are going to need them when make our API call. Note: you can use either <strong>KEY 1</strong> or <strong>KEY 2</strong> as your subscription key</p>
<p>To begin our transcription, install the packages we are going to need if you don’t have them already installed:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Enables us to work with HTTP in R</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">"httr"</span>) </span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">"jsonlite"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Note</strong> You will have to modify the subscription key, language and data path parameters to match the ones on the Cognitive Services resource you created earlier. Also modify the URL <code>'https://eastus.stt.speech.microsoft.com/speech/recognition/conversation/cognitiveservices/v1'</code> by inserting the aforementioned location details as shown in the modified URL : <code>'https://_ENTER_LOCATION_HERE_.stt.speech.microsoft.com/speech/recognition/conversation/cognitiveservices/v1'</code> . At the end you should have something like this:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(httr)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(jsonlite)  </span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Documentation on the two packages can be found by running ?httr and ?jsonlite commands respectively on the console.</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="co">#Define headers containing subscription key and content type</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>headers <span class="ot">=</span> <span class="fu">c</span>(</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>  <span class="st">`</span><span class="at">Ocp-Apim-Subscription-Key</span><span class="st">`</span> <span class="ot">=</span> <span class="st">'_ENTER_YOUR_SUBSCRIPTION_KEY_HERE'</span>,  <span class="co">#Key 1 or 2</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>  <span class="st">`</span><span class="at">Content-Type</span><span class="st">`</span> <span class="ot">=</span> <span class="st">'audio/wav'</span> <span class="co">#Since we are transcribing a WAV file</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a><span class="co">#Create a parameters list, in this case we specify the languange parameter</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>params <span class="ot">=</span> <span class="fu">list</span>(</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>  <span class="st">`</span><span class="at">language</span><span class="st">`</span> <span class="ot">=</span> <span class="st">'en-US'</span></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a><span class="co">#Enter path to the audio file we just recorded and saved</span></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> <span class="fu">upload_file</span> (<span class="st">'Insert_path_to_sample.wav_here'</span>) </span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a><span class="co">#Make the API call and save the response recived</span></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>response <span class="ot">&lt;-</span> httr<span class="sc">::</span><span class="fu">POST</span>(<span class="at">url =</span> <span class="st">'https://eastus.stt.speech.microsoft.com/speech/recognition/conversation/cognitiveservices/v1'</span>, </span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>httr<span class="sc">::</span><span class="fu">add_headers</span>(<span class="at">.headers=</span>headers), <span class="at">query =</span> params, <span class="at">body =</span> data)</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a><span class="co">#Convert response received to a dataframe</span></span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>result <span class="ot">&lt;-</span> <span class="fu">fromJSON</span>(<span class="fu">content</span>(response, <span class="at">as  =</span> <span class="st">'text'</span>)) </span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>txt_output <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(result)</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a><span class="co">#Extract transcribed text</span></span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>txt_input <span class="ot">&lt;-</span> txt_output[<span class="dv">1</span>,<span class="dv">2</span>]</span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>txt_input</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>And with that, we have successfully recorded audio and transcribed it with the aid of Microsoft Azure Cognitive Services. The applications of the cognitive services are wide and this is just but a glimpse of what one can accomplish using the Speech to Text service. I’ll leave it at that. Thank you foR youR time. Cheers.</p>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./index.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Preface</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./02_kinematics.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Manipulator kinematics</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb11" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Speech to text"</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Ian Muchiri and Eric Wanjau"</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="an">toc:</span><span class="co"> true</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="an">number-sections:</span><span class="co"> true</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="an">highlight-style:</span><span class="co"> pygments</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="co">  html: </span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="co">    code-fold: false</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="co">    code-tools: true</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="co">    html-math-method: katex</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a><span class="co">  pdf:</span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a><span class="co">    geometry: </span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="co">      - top=30mm</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="co">      - left=30mm</span></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a><span class="co">  docx: default</span></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="an">execute:</span><span class="co"> </span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a><span class="co">  eval: false</span></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a><span class="co">  warning: false</span></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a><span class="co">  message: false</span></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>This notebook contains a step by step guide on how to record audio in R using the <span class="co">[</span><span class="ot">audio package</span><span class="co">](https://cran.r-project.org/web/packages/audio/audio.pdf)</span> and convert the recording to text using Microsoft Azure Cognitive Services, specifically the <span class="co">[</span><span class="ot">speech-to-text service</span><span class="co">](https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/rest-speech-to-text-short)</span>.</span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a><span class="fu">## Introduction</span></span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>I recently found myself working on a chess play automation project. The user would issue a voice command describing the location of the piece they want to move and their desired destination location, the data would then processed and a chess move made. This was so cool and being the R-nista that I am (i don't think this is a word, i have only come across Pythonistas ) ,I thought to myself, maybe this can also be done in R and voila, this article was born. For any feedback feel free to reach out at <span class="co">[</span><span class="ot">Ian</span><span class="co">](https://twitter.com/Entity_4004)</span></span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a><span class="fu">## Recording Audio in R using the audio Package</span></span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>We begin with the input which we plan to transcribe. In order to record audio,we need to install and load the audio package</span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a><span class="co">#install the audio package</span></span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">"audio"</span>)</span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a>We then proceed to setup the audio driver which we will use to record as shown below:</span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-46"><a href="#cb11-46" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb11-47"><a href="#cb11-47" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb11-48"><a href="#cb11-48" aria-hidden="true" tabindex="-1"></a><span class="co">#Load the library</span></span>
<span id="cb11-49"><a href="#cb11-49" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(audio)</span>
<span id="cb11-50"><a href="#cb11-50" aria-hidden="true" tabindex="-1"></a><span class="co">#Check which audio driver is set</span></span>
<span id="cb11-51"><a href="#cb11-51" aria-hidden="true" tabindex="-1"></a><span class="fu">current.audio.driver</span>()</span>
<span id="cb11-52"><a href="#cb11-52" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-53"><a href="#cb11-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-56"><a href="#cb11-56" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb11-57"><a href="#cb11-57" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb11-58"><a href="#cb11-58" aria-hidden="true" tabindex="-1"></a><span class="co">#if there is no driver set, view what drivers are available</span></span>
<span id="cb11-59"><a href="#cb11-59" aria-hidden="true" tabindex="-1"></a><span class="fu">audio.drivers</span>()</span>
<span id="cb11-60"><a href="#cb11-60" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-61"><a href="#cb11-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-64"><a href="#cb11-64" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb11-65"><a href="#cb11-65" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb11-66"><a href="#cb11-66" aria-hidden="true" tabindex="-1"></a><span class="co">#from the list provided, set which driver to use (default driver is always best)</span></span>
<span id="cb11-67"><a href="#cb11-67" aria-hidden="true" tabindex="-1"></a><span class="fu">set.audio.driver</span>(<span class="cn">NULL</span>)<span class="co"># sets the default audio driver</span></span>
<span id="cb11-68"><a href="#cb11-68" aria-hidden="true" tabindex="-1"></a><span class="co">#option 2</span></span>
<span id="cb11-69"><a href="#cb11-69" aria-hidden="true" tabindex="-1"></a><span class="fu">set.audio.driver</span> (insert_name_here ) <span class="co">#sets the audio driver to a driver other than the default</span></span>
<span id="cb11-70"><a href="#cb11-70" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-71"><a href="#cb11-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-74"><a href="#cb11-74" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb11-75"><a href="#cb11-75" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb11-76"><a href="#cb11-76" aria-hidden="true" tabindex="-1"></a><span class="co">#Checks and verifies that indeed the audio driver is set as per the command above</span></span>
<span id="cb11-77"><a href="#cb11-77" aria-hidden="true" tabindex="-1"></a><span class="fu">current.audio.driver</span>() </span>
<span id="cb11-78"><a href="#cb11-78" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-79"><a href="#cb11-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-80"><a href="#cb11-80" aria-hidden="true" tabindex="-1"></a><span class="fu">### Recording Audio</span></span>
<span id="cb11-81"><a href="#cb11-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-82"><a href="#cb11-82" aria-hidden="true" tabindex="-1"></a>Some of the key parameters in audio processing which we are going to encounter during this exercise include:</span>
<span id="cb11-83"><a href="#cb11-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-84"><a href="#cb11-84" aria-hidden="true" tabindex="-1"></a>**Sample rate:** This is the number of times per second a sound is sampled and recorded.Therefore, if we use a sampling rate of say 8000 Hertz, a recording with a duration of 5 seconds will contain 40,000 samples (8000 <span class="sc">\*</span> 5). The industry standard sampling rate commonly used is 44100 Hertz.</span>
<span id="cb11-85"><a href="#cb11-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-86"><a href="#cb11-86" aria-hidden="true" tabindex="-1"></a>**Mono vs Stereo:** If you are a sound enthusiast, you've probably come across these terms. Simply put, Mono sound is recorded and played back using only *one audio channel* e.g. a guitarist recording using one mic to pick up sound of the guitar and Stereo sound is recorded and played through *more than one channel.*</span>
<span id="cb11-87"><a href="#cb11-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-88"><a href="#cb11-88" aria-hidden="true" tabindex="-1"></a>In our case we will use one audio channel(mono) and a sampling rate of 44100Hz. That being said let's start our recording</span>
<span id="cb11-89"><a href="#cb11-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-92"><a href="#cb11-92" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb11-93"><a href="#cb11-93" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb11-94"><a href="#cb11-94" aria-hidden="true" tabindex="-1"></a><span class="co">#Set our recording time</span></span>
<span id="cb11-95"><a href="#cb11-95" aria-hidden="true" tabindex="-1"></a>rec_time <span class="ot">&lt;-</span> <span class="dv">5</span> </span>
<span id="cb11-96"><a href="#cb11-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-97"><a href="#cb11-97" aria-hidden="true" tabindex="-1"></a><span class="co">#Recording</span></span>
<span id="cb11-98"><a href="#cb11-98" aria-hidden="true" tabindex="-1"></a>Samples<span class="ot">&lt;-</span><span class="fu">rep</span>(<span class="cn">NA_real_</span>, <span class="dv">44100</span> <span class="sc">*</span> rec_time) <span class="co">#Defining number of samples recorded</span></span>
<span id="cb11-99"><a href="#cb11-99" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="st">"Start speaking"</span>)</span>
<span id="cb11-100"><a href="#cb11-100" aria-hidden="true" tabindex="-1"></a>audio_obj <span class="ot">&lt;-</span><span class="fu">record</span>(Samples, <span class="dv">44100</span>, <span class="dv">1</span>) <span class="co">#Create an audio instance with sample rate 44100 and mono channel</span></span>
<span id="cb11-101"><a href="#cb11-101" aria-hidden="true" tabindex="-1"></a><span class="fu">wait</span>(<span class="dv">6</span>)</span>
<span id="cb11-102"><a href="#cb11-102" aria-hidden="true" tabindex="-1"></a>rec <span class="ot">&lt;-</span> audio_obj<span class="sc">$</span>data <span class="co"># get the recorded data from the audio object</span></span>
<span id="cb11-103"><a href="#cb11-103" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb11-104"><a href="#cb11-104" aria-hidden="true" tabindex="-1"></a><span class="co">#Save the recorded audio</span></span>
<span id="cb11-105"><a href="#cb11-105" aria-hidden="true" tabindex="-1"></a><span class="fu">file.create</span>(<span class="st">"sample.wav"</span>)<span class="co">#gets created in your current working directory </span></span>
<span id="cb11-106"><a href="#cb11-106" aria-hidden="true" tabindex="-1"></a><span class="fu">save.wave</span>(rec,<span class="st">"Insert_path_to_sample.wav_here"</span>)</span>
<span id="cb11-107"><a href="#cb11-107" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-108"><a href="#cb11-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-109"><a href="#cb11-109" aria-hidden="true" tabindex="-1"></a>On recording and saving the audio file to <span class="in">`sample.wav`</span> , we have to clear the audio instance object <span class="in">`audio_obj`</span> before proceeding to make the next recording. From the audio package documentation, this is achieved by using the <span class="in">`close(con,…)`</span> method, where <span class="in">`con`</span> is the audioInstance object .However, using this method proved to be cumbersome as it causes the console to freeze anytime you want to record audio for more than one time. After doing some research, I discovered that restarting the console clears the audio instance object therefore allowing for one to record audio multiple times with no issue. I know this is not an elegant solution (more like tying duct tape around a leaking pipe )and i am actively looking for a better solution to fix this issue. For now, we go by the saying: if it works, don't touch it and implement this step to clear the audio instance object.</span>
<span id="cb11-110"><a href="#cb11-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-113"><a href="#cb11-113" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb11-114"><a href="#cb11-114" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb11-115"><a href="#cb11-115" aria-hidden="true" tabindex="-1"></a><span class="fu">.rs.restartR</span>() <span class="co"># clear the audio instance object(looking for a more elegant solution)</span></span>
<span id="cb11-116"><a href="#cb11-116" aria-hidden="true" tabindex="-1"></a><span class="fu">wait</span>(<span class="dv">3</span>)</span>
<span id="cb11-117"><a href="#cb11-117" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-118"><a href="#cb11-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-119"><a href="#cb11-119" aria-hidden="true" tabindex="-1"></a>Play the recording we just created just to confirm that indeed we recorded something.</span>
<span id="cb11-120"><a href="#cb11-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-123"><a href="#cb11-123" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb11-124"><a href="#cb11-124" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb11-125"><a href="#cb11-125" aria-hidden="true" tabindex="-1"></a><span class="fu">play</span>(rec)</span>
<span id="cb11-126"><a href="#cb11-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-127"><a href="#cb11-127" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-128"><a href="#cb11-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-129"><a href="#cb11-129" aria-hidden="true" tabindex="-1"></a>That's it for our input. We now proceed to process this and transcribe the audio we just recorded</span>
<span id="cb11-130"><a href="#cb11-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-131"><a href="#cb11-131" aria-hidden="true" tabindex="-1"></a><span class="fu">## House Keeping on Azure</span></span>
<span id="cb11-132"><a href="#cb11-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-133"><a href="#cb11-133" aria-hidden="true" tabindex="-1"></a>First we begin with some light housekeeping, i.e setting up a <span class="co">[</span><span class="ot">Cognitive Services resource</span><span class="co">](https://docs.microsoft.com/en-us/azure/cognitive-services/what-are-cognitive-services)</span> in our Azure subscription. You can create a free Azure account <span class="co">[</span><span class="ot">here</span><span class="co">](https://azure.microsoft.com/en-gb/)</span> and if you have an account already, you can skip this step.</span>
<span id="cb11-134"><a href="#cb11-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-135"><a href="#cb11-135" aria-hidden="true" tabindex="-1"></a>We then proceed to create a cognitive resource group by following these steps:$<span class="sc">\\</span>$ 1. Open the Azure portal <span class="in">`https://portal.azure.com`</span> and sign in using your Microsoft account.$<span class="sc">\\</span>$ 2. Click **+ Create a resource** and on the search bar, type **Speech**, click **create** and create a Cognitive service resource with the following settings:</span>
<span id="cb11-136"><a href="#cb11-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-137"><a href="#cb11-137" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Subscription: *Enter your Azure subscription*</span>
<span id="cb11-138"><a href="#cb11-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-139"><a href="#cb11-139" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Resource group: *Create one with a unique name or an existing one*</span>
<span id="cb11-140"><a href="#cb11-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-141"><a href="#cb11-141" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Region: *Choose any*</span>
<span id="cb11-142"><a href="#cb11-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-143"><a href="#cb11-143" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Name: *Enter a unique name*</span>
<span id="cb11-144"><a href="#cb11-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-145"><a href="#cb11-145" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Pricing tier: *Standard S0*</span>
<span id="cb11-146"><a href="#cb11-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-147"><a href="#cb11-147" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Select I have read and understood the notices</span>
<span id="cb11-148"><a href="#cb11-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-149"><a href="#cb11-149" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Click on **Review + create** and we are good to go.</span>
<span id="cb11-150"><a href="#cb11-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-151"><a href="#cb11-151" aria-hidden="true" tabindex="-1"></a>As a guide, these are the settings I used however, you can go ahead and get creative with the names.</span>
<span id="cb11-152"><a href="#cb11-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-153"><a href="#cb11-153" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/creating%20speech%20service.png)</span></span>
<span id="cb11-154"><a href="#cb11-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-155"><a href="#cb11-155" aria-hidden="true" tabindex="-1"></a><span class="fu">## Speech-to-text API call</span></span>
<span id="cb11-156"><a href="#cb11-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-157"><a href="#cb11-157" aria-hidden="true" tabindex="-1"></a>Since now we have our audio sample input <span class="in">`sample.wav`</span> ,we can now go ahead to the transcribing bit. It is noteworthy that the speech to text rest API for short audio has several limitations which are:</span>
<span id="cb11-158"><a href="#cb11-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-159"><a href="#cb11-159" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Requests cannot contain more than 60 seconds of audio. For batch transcriptions and custom speech use <span class="co">[</span><span class="ot">Speech to Text API v3.0</span><span class="co">](https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/rest-speech-to-text)</span></span>
<span id="cb11-160"><a href="#cb11-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-161"><a href="#cb11-161" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The API does not provide partial results.</span>
<span id="cb11-162"><a href="#cb11-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-163"><a href="#cb11-163" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>It does not support Speech translation. For translation, you can checkout the <span class="co">[</span><span class="ot">Speech SDK</span><span class="co">](https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/speech-sdk)</span></span>
<span id="cb11-164"><a href="#cb11-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-165"><a href="#cb11-165" aria-hidden="true" tabindex="-1"></a>Now that we are done with that, we can then go ahead and get coding.</span>
<span id="cb11-166"><a href="#cb11-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-167"><a href="#cb11-167" aria-hidden="true" tabindex="-1"></a>**`Note:`** To access the speech service we just created from R, we need the **URL of the endpoint**, **location/region details** and **KEY 1 &amp; 2** parameters. These can be found in the azure portal under **Keys and Endpoint** page of your cognitive service resource as illustrated below:</span>
<span id="cb11-168"><a href="#cb11-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-169"><a href="#cb11-169" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/keys%20and%20endpoints.png)</span></span>
<span id="cb11-170"><a href="#cb11-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-171"><a href="#cb11-171" aria-hidden="true" tabindex="-1"></a>Copy these details and save them since we are going to need them when make our API call. Note: you can use either **KEY 1** or **KEY 2** as your subscription key</span>
<span id="cb11-172"><a href="#cb11-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-173"><a href="#cb11-173" aria-hidden="true" tabindex="-1"></a>To begin our transcription, install the packages we are going to need if you don't have them already installed:</span>
<span id="cb11-174"><a href="#cb11-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-177"><a href="#cb11-177" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb11-178"><a href="#cb11-178" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb11-179"><a href="#cb11-179" aria-hidden="true" tabindex="-1"></a><span class="co">#Enables us to work with HTTP in R</span></span>
<span id="cb11-180"><a href="#cb11-180" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">"httr"</span>) </span>
<span id="cb11-181"><a href="#cb11-181" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">"jsonlite"</span>)</span>
<span id="cb11-182"><a href="#cb11-182" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-183"><a href="#cb11-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-184"><a href="#cb11-184" aria-hidden="true" tabindex="-1"></a>**Note** You will have to modify the subscription key, language and data path parameters to match the ones on the Cognitive Services resource you created earlier. Also modify the URL <span class="in">`'https://eastus.stt.speech.microsoft.com/speech/recognition/conversation/cognitiveservices/v1'`</span> by inserting the aforementioned location details as shown in the modified URL : <span class="in">`'https://_ENTER_LOCATION_HERE_.stt.speech.microsoft.com/speech/recognition/conversation/cognitiveservices/v1'`</span> . At the end you should have something like this:</span>
<span id="cb11-185"><a href="#cb11-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-188"><a href="#cb11-188" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb11-189"><a href="#cb11-189" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb11-190"><a href="#cb11-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-191"><a href="#cb11-191" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(httr)</span>
<span id="cb11-192"><a href="#cb11-192" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(jsonlite)  </span>
<span id="cb11-193"><a href="#cb11-193" aria-hidden="true" tabindex="-1"></a><span class="co">#Documentation on the two packages can be found by running ?httr and ?jsonlite commands respectively on the console.</span></span>
<span id="cb11-194"><a href="#cb11-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-195"><a href="#cb11-195" aria-hidden="true" tabindex="-1"></a><span class="co">#Define headers containing subscription key and content type</span></span>
<span id="cb11-196"><a href="#cb11-196" aria-hidden="true" tabindex="-1"></a>headers <span class="ot">=</span> <span class="fu">c</span>(</span>
<span id="cb11-197"><a href="#cb11-197" aria-hidden="true" tabindex="-1"></a>  <span class="st">`</span><span class="at">Ocp-Apim-Subscription-Key</span><span class="st">`</span> <span class="ot">=</span> <span class="st">'_ENTER_YOUR_SUBSCRIPTION_KEY_HERE'</span>,  <span class="co">#Key 1 or 2</span></span>
<span id="cb11-198"><a href="#cb11-198" aria-hidden="true" tabindex="-1"></a>  <span class="st">`</span><span class="at">Content-Type</span><span class="st">`</span> <span class="ot">=</span> <span class="st">'audio/wav'</span> <span class="co">#Since we are transcribing a WAV file</span></span>
<span id="cb11-199"><a href="#cb11-199" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb11-200"><a href="#cb11-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-201"><a href="#cb11-201" aria-hidden="true" tabindex="-1"></a><span class="co">#Create a parameters list, in this case we specify the languange parameter</span></span>
<span id="cb11-202"><a href="#cb11-202" aria-hidden="true" tabindex="-1"></a>params <span class="ot">=</span> <span class="fu">list</span>(</span>
<span id="cb11-203"><a href="#cb11-203" aria-hidden="true" tabindex="-1"></a>  <span class="st">`</span><span class="at">language</span><span class="st">`</span> <span class="ot">=</span> <span class="st">'en-US'</span></span>
<span id="cb11-204"><a href="#cb11-204" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb11-205"><a href="#cb11-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-206"><a href="#cb11-206" aria-hidden="true" tabindex="-1"></a><span class="co">#Enter path to the audio file we just recorded and saved</span></span>
<span id="cb11-207"><a href="#cb11-207" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> <span class="fu">upload_file</span> (<span class="st">'Insert_path_to_sample.wav_here'</span>) </span>
<span id="cb11-208"><a href="#cb11-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-209"><a href="#cb11-209" aria-hidden="true" tabindex="-1"></a><span class="co">#Make the API call and save the response recived</span></span>
<span id="cb11-210"><a href="#cb11-210" aria-hidden="true" tabindex="-1"></a>response <span class="ot">&lt;-</span> httr<span class="sc">::</span><span class="fu">POST</span>(<span class="at">url =</span> <span class="st">'https://eastus.stt.speech.microsoft.com/speech/recognition/conversation/cognitiveservices/v1'</span>, </span>
<span id="cb11-211"><a href="#cb11-211" aria-hidden="true" tabindex="-1"></a>httr<span class="sc">::</span><span class="fu">add_headers</span>(<span class="at">.headers=</span>headers), <span class="at">query =</span> params, <span class="at">body =</span> data)</span>
<span id="cb11-212"><a href="#cb11-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-213"><a href="#cb11-213" aria-hidden="true" tabindex="-1"></a><span class="co">#Convert response received to a dataframe</span></span>
<span id="cb11-214"><a href="#cb11-214" aria-hidden="true" tabindex="-1"></a>result <span class="ot">&lt;-</span> <span class="fu">fromJSON</span>(<span class="fu">content</span>(response, <span class="at">as  =</span> <span class="st">'text'</span>)) </span>
<span id="cb11-215"><a href="#cb11-215" aria-hidden="true" tabindex="-1"></a>txt_output <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(result)</span>
<span id="cb11-216"><a href="#cb11-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-217"><a href="#cb11-217" aria-hidden="true" tabindex="-1"></a><span class="co">#Extract transcribed text</span></span>
<span id="cb11-218"><a href="#cb11-218" aria-hidden="true" tabindex="-1"></a>txt_input <span class="ot">&lt;-</span> txt_output[<span class="dv">1</span>,<span class="dv">2</span>]</span>
<span id="cb11-219"><a href="#cb11-219" aria-hidden="true" tabindex="-1"></a>txt_input</span>
<span id="cb11-220"><a href="#cb11-220" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-221"><a href="#cb11-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-222"><a href="#cb11-222" aria-hidden="true" tabindex="-1"></a>And with that, we have successfully recorded audio and transcribed it with the aid of Microsoft Azure Cognitive Services. The applications of the cognitive services are wide and this is just but a glimpse of what one can accomplish using the Speech to Text service. I'll leave it at that. Thank you foR youR time. Cheers.</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>